"""
cardiac_v100_onefile.py
-----------------------
one-file, research-grade-ish pipeline for:
  - physiologically informed synthetic cardiac current generation (time-aware, myocardium geometry)
  - biot-savart forward model (fft, cached)
  - kiel-cardio-compatible sensor sampling + preprocessing filters
  - training: inversion (B->J) + classification (disease) + domain adaptation hooks (kiel unlabeled)
  - evaluation: metrics, confusion matrix, calibration

requirements:
  - python 3.9+
  - torch, numpy
optional:
  - wfdb (to load kiel-cardio wfdb files)
    pip install wfdb

notes:
  - kiel-cardio v1.0.0 contains healthy subjects only (no disease labels). use it for domain adaptation / realism checks.
"""

from __future__ import annotations

import os
import re
import math
import time
import glob
import json
import random
import argparse
from dataclasses import dataclass, asdict
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# -------------------------
# utils
# -------------------------

def seed_all(seed: int = 0) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def device_of(x: torch.Tensor) -> torch.device:
    return x.device

def to_device(batch: Any, device: torch.device):
    if isinstance(batch, torch.Tensor):
        return batch.to(device)
    if isinstance(batch, (list, tuple)):
        return type(batch)(to_device(v, device) for v in batch)
    if isinstance(batch, dict):
        return {k: to_device(v, device) for k, v in batch.items()}
    return batch

def pretty_time(sec: float) -> str:
    if sec < 60:
        return f"{sec:.1f}s"
    if sec < 3600:
        return f"{sec/60:.1f}m"
    return f"{sec/3600:.1f}h"

def exists(x) -> bool:
    return x is not None

# -------------------------
# config
# -------------------------

@dataclass
class TrainConfig:
    seed: int = 0
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

    # data
    grid_size: int = 24                  # 24 or 32 is realistic; 16 is faster
    n_samples: int = 1200                # total synthetic samples
    classes: Tuple[str, ...] = ("normal", "ischemia", "arrhythmia", "hypertrophy")

    # time-series (synthetic)
    fs: int = 200                        # match kiel fs
    seconds: int = 6                     # synthetic window length; keep small for training
    heart_rate_bpm_range: Tuple[float, float] = (55.0, 95.0)

    # sensors
    use_sensor_observations: bool = True
    sensor_mode: str = "kiel"            # "kiel" or "random"
    sensor_noise_std: float = 0.02       # relative
    drift_strength: float = 0.015
    line_noise_strength: float = 0.015   # 50Hz
    domain_randomize_filters: bool = True

    # model
    inv_model: str = "spectral3d"        # "spectral3d"
    inv_width: int = 48
    inv_depth: int = 4
    inv_modes: int = 10

    clf_model: str = "cnn3d"             # "cnn3d" or "sensor_transformer"
    clf_width: int = 48

    # training
    batch_size: int = 8
    num_workers: int = 0
    epochs_inv: int = 20
    epochs_clf: int = 25
    lr: float = 2e-4
    weight_decay: float = 1e-3
    grad_clip: float = 1.0
    ema_decay: float = 0.995
    label_smoothing: float = 0.03
    focal_gamma: float = 1.5
    class_weight_ischemia_boost: float = 1.5

    # losses
    lambda_div: float = 0.25             # divergence penalty on J
    lambda_smooth: float = 0.05          # smoothness penalty on J

    # augment
    mixup_alpha: float = 0.2
    aug_shift_vox: int = 2
    aug_noise_vox: float = 0.02

    # eval
    val_frac: float = 0.15
    test_frac: float = 0.15
    early_stop_patience: int = 8

    # kiel
    kiel_root: Optional[str] = None      # path to extracted kiel-cardio/1.0.0 folder
    kiel_use_preprocessed: bool = True
    kiel_max_records: int = 200          # for fast sanity

# -------------------------
# metrics
# -------------------------

@torch.no_grad()
def confusion_matrix(pred: torch.Tensor, true: torch.Tensor, n_classes: int) -> torch.Tensor:
    cm = torch.zeros(n_classes, n_classes, dtype=torch.long)
    for t, p in zip(true.view(-1), pred.view(-1)):
        cm[t.long(), p.long()] += 1
    return cm

@torch.no_grad()
def classification_report_from_cm(cm: torch.Tensor, class_names: List[str]) -> Dict[str, Any]:
    # cm: [T,P]
    eps = 1e-12
    n = cm.sum().item()
    correct = cm.diag().sum().item()
    acc = correct / max(n, 1)

    per_class = {}
    for i, name in enumerate(class_names):
        tp = cm[i, i].item()
        fn = cm[i, :].sum().item() - tp
        fp = cm[:, i].sum().item() - tp
        prec = tp / max(tp + fp, 1)
        rec = tp / max(tp + fn, 1)
        f1 = (2 * prec * rec) / max(prec + rec, eps)
        per_class[name] = {"precision": prec, "recall": rec, "f1": f1, "support": int(cm[i, :].sum().item())}

    macro_f1 = float(np.mean([per_class[n]["f1"] for n in class_names]))
    macro_rec = float(np.mean([per_class[n]["recall"] for n in class_names]))
    macro_prec = float(np.mean([per_class[n]["precision"] for n in class_names]))

    return {
        "accuracy": acc,
        "macro_precision": macro_prec,
        "macro_recall": macro_rec,
        "macro_f1": macro_f1,
        "per_class": per_class,
    }

# -------------------------
# signal filtering (kiel-like)
# -------------------------

def _sinc(x: torch.Tensor) -> torch.Tensor:
    return torch.where(x == 0, torch.ones_like(x), torch.sin(math.pi * x) / (math.pi * x))

def design_fir_lowpass(fs: int, cutoff_hz: float, taps: int = 401, device="cpu") -> torch.Tensor:
    # windowed sinc (hamming)
    t = torch.arange(taps, device=device) - (taps - 1) / 2
    fc = cutoff_hz / fs
    h = 2 * fc * _sinc(2 * fc * t)
    w = 0.54 - 0.46 * torch.cos(2 * math.pi * torch.arange(taps, device=device) / (taps - 1))
    h = h * w
    h = h / (h.sum() + 1e-12)
    return h

def design_fir_highpass(fs: int, cutoff_hz: float, taps: int = 401, device="cpu") -> torch.Tensor:
    lp = design_fir_lowpass(fs, cutoff_hz, taps=taps, device=device)
    hp = -lp
    hp[(taps - 1)//2] += 1.0
    return hp

def design_fir_notch(fs: int, center_hz: float, width_hz: float = 2.0, taps: int = 801, device="cpu") -> torch.Tensor:
    # notch = 1 - bandpass; bandpass = lp(f2) - lp(f1)
    f1 = max(0.1, center_hz - width_hz/2)
    f2 = min(fs/2 - 0.1, center_hz + width_hz/2)
    lp2 = design_fir_lowpass(fs, f2, taps=taps, device=device)
    lp1 = design_fir_lowpass(fs, f1, taps=taps, device=device)
    bp = lp2 - lp1
    notch = -bp
    notch[(taps - 1)//2] += 1.0
    notch = notch / (notch.sum() + 1e-12)
    return notch

def apply_fir(x: torch.Tensor, h: torch.Tensor) -> torch.Tensor:
    """
    x: (B, C, T)
    h: (K,)
    """
    k = h.numel()
    pad = (k - 1)//2
    x_pad = F.pad(x, (pad, pad), mode="reflect")
    h_ = h.view(1, 1, -1).to(x.device, x.dtype)
    y = F.conv1d(x_pad, h_.repeat(x.shape[1], 1, 1), groups=x.shape[1])
    return y

def kiel_preprocess(x: torch.Tensor, fs: int, device=None, randomize: bool = False) -> torch.Tensor:
    """
    emulate kiel preprocessing:
      - 1 Hz high-pass
      - 100 Hz low-pass
      - 50 Hz band-stop
    x: (B, C, T)
    """
    dev = x.device if device is None else device
    # small domain randomization on cutoffs/taps can help sim2real
    hp_cut = 1.0 * (np.random.uniform(0.8, 1.2) if randomize else 1.0)
    lp_cut = 100.0 * (np.random.uniform(0.9, 1.05) if randomize else 1.0)
    notch_c = 50.0 * (np.random.uniform(0.98, 1.02) if randomize else 1.0)
    notch_w = 2.0 * (np.random.uniform(0.8, 1.5) if randomize else 1.0)

    hp = design_fir_highpass(fs, hp_cut, taps=401, device=dev)
    lp = design_fir_lowpass(fs, min(lp_cut, fs/2-1), taps=401, device=dev)
    nt = design_fir_notch(fs, notch_c, width_hz=notch_w, taps=801, device=dev)

    y = apply_fir(x, hp)
    y = apply_fir(y, nt)
    y = apply_fir(y, lp)
    return y

# -------------------------
# geometry + physics helpers
# -------------------------

def make_grid(n: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    x = torch.linspace(-1, 1, n, device=device)
    X, Y, Z = torch.meshgrid(x, x, x, indexing="ij")
    return X, Y, Z

def smooth_3d(x: torch.Tensor, sigma: float = 1.0) -> torch.Tensor:
    # cheap approximation: repeated avg pooling
    if sigma <= 0:
        return x
    if x.dim() == 4:  # (C,X,Y,Z)
        x = x.unsqueeze(0)
        squeeze = True
    elif x.dim() == 3:  # (X,Y,Z)
        x = x.unsqueeze(0).unsqueeze(0)
        squeeze = "3d"
    else:
        squeeze = False

    passes = int(max(1, round(sigma)))
    for _ in range(passes):
        x = F.avg_pool3d(x, kernel_size=3, stride=1, padding=1)

    if squeeze is True:
        return x.squeeze(0)
    if squeeze == "3d":
        return x.squeeze(0).squeeze(0)
    return x

def finite_diff(x: torch.Tensor, axis: int) -> torch.Tensor:
    return (torch.roll(x, -1, axis) - torch.roll(x, 1, axis)) / 2.0

def curl_of_A(A: torch.Tensor) -> torch.Tensor:
    # A: (3,X,Y,Z) -> J: (3,X,Y,Z)
    Ax, Ay, Az = A[0], A[1], A[2]
    dAz_dy = finite_diff(Az, 1)
    dAy_dz = finite_diff(Ay, 2)
    dAx_dz = finite_diff(Ax, 2)
    dAz_dx = finite_diff(Az, 0)
    dAy_dx = finite_diff(Ay, 0)
    dAx_dy = finite_diff(Ax, 1)
    Jx = dAz_dy - dAy_dz
    Jy = dAx_dz - dAz_dx
    Jz = dAy_dx - dAx_dy
    return torch.stack([Jx, Jy, Jz], dim=0)

def divergence(J: torch.Tensor) -> torch.Tensor:
    # J: (3,X,Y,Z)
    dJx_dx = finite_diff(J[0], 0)
    dJy_dy = finite_diff(J[1], 1)
    dJz_dz = finite_diff(J[2], 2)
    return dJx_dx + dJy_dy + dJz_dz

def gradient_scalar(s: torch.Tensor) -> torch.Tensor:
    # s: (X,Y,Z) -> (3,X,Y,Z)
    return torch.stack([finite_diff(s,0), finite_diff(s,1), finite_diff(s,2)], dim=0)

def myocardium_mask(n: int, device: torch.device) -> torch.Tensor:
    """
    crude ventricular shell: outer ellipsoid minus inner cavity ellipsoid.
    returns mask in [0,1], shape (X,Y,Z)
    """
    X, Y, Z = make_grid(n, device)
    # outer ellipsoid
    a, b, c = 0.85, 0.7, 0.85
    outer = (X/a)**2 + (Y/b)**2 + (Z/c)**2
    # inner cavity
    ai, bi, ci = 0.55, 0.45, 0.60
    inner = ((X+0.05)/ai)**2 + (Y/bi)**2 + ((Z-0.05)/ci)**2
    shell = torch.sigmoid(18*(1-outer)) * torch.sigmoid(18*(inner-1))
    shell = smooth_3d(shell, 1.5)
    shell = shell / (shell.max() + 1e-8)
    return shell.clamp(0,1)

def fiber_field(n: int, device: torch.device) -> torch.Tensor:
    """
    geometry-aware-ish helix: fiber rotates across transmural depth.
    returns (3,X,Y,Z) unit vectors
    """
    X, Y, Z = make_grid(n, device)
    r = torch.sqrt(X**2 + Y**2) + 1e-6
    depth = (1 - r).clamp(0,1)  # fake transmural coordinate
    helix_angle = (depth * math.pi/2) - (math.pi/4)
    fx = -Y/r * torch.cos(helix_angle)
    fy =  X/r * torch.cos(helix_angle)
    fz = torch.sin(helix_angle) * 0.35
    f = torch.stack([fx, fy, fz], dim=0)
    f = f / (f.norm(dim=0, keepdim=True) + 1e-8)
    return f

# -------------------------
# synthetic electrophysiology proxy
# -------------------------

def activation_time_field(n: int, device: torch.device, mode: str = "normal") -> torch.Tensor:
    """
    generate activation time T(x) in seconds (X,Y,Z).
    normal: planar-ish wave + slight curvature.
    arrhythmia: reentry-like phase spiral projected into 3d.
    """
    X, Y, Z = make_grid(n, device)
    if mode == "arrhythmia":
        # spiral in XY around a core, with z gradient
        cx, cy = np.random.uniform(-0.2, 0.2), np.random.uniform(-0.2, 0.2)
        theta = torch.atan2(Y - cy, X - cx)
        r = torch.sqrt((X - cx)**2 + (Y - cy)**2) + 1e-6
        spiral = (theta / (2*math.pi) + 0.35 * r).remainder(1.0)
        T = 0.18 * spiral + 0.05 * (Z + 1)/2
        T = smooth_3d(T, 1.0)
        return T
    else:
        # wavefront direction random
        nx, ny, nz = np.random.uniform(-1,1), np.random.uniform(-1,1), np.random.uniform(-0.5,0.5)
        v = torch.tensor([nx, ny, nz], device=device, dtype=torch.float32)
        v = v / (v.norm() + 1e-8)
        phase = v[0]*X + v[1]*Y + v[2]*Z
        # curvature
        curv = 0.12 * (X**2 - 0.5*Y**2) + 0.05*Z*X
        T = 0.18 * (phase + curv - phase.min()) / ((phase + curv).max() - (phase + curv).min() + 1e-8)
        T = smooth_3d(T, 1.0)
        return T

def transmembrane_proxy(t: torch.Tensor, Tact: torch.Tensor, apd: float = 0.28) -> torch.Tensor:
    """
    very rough V(t,x) from activation time:
      - sharp upstroke at (t - Tact) ~ 0
      - decay after APD
    """
    dt = t - Tact
    up = torch.sigmoid(60 * dt)
    rep = torch.sigmoid(50 * (dt - apd))
    V = up * (1 - rep)
    return V

def synthesize_J_time_series(
    n: int,
    device: torch.device,
    fs: int,
    seconds: int,
    pathology: str,
) -> Tuple[torch.Tensor, Dict[str, Any]]:
    """
    returns:
      J: (T,3,X,Y,Z)
      meta dict
    """
    T = int(fs * seconds)
    tvec = torch.linspace(0, seconds, T, device=device)

    myo = myocardium_mask(n, device)  # (X,Y,Z)
    fib = fiber_field(n, device)      # (3,X,Y,Z)

    # base activation
    act_mode = "arrhythmia" if pathology == "arrhythmia" else "normal"
    Tact = activation_time_field(n, device, mode=act_mode)

    # pathology modifiers
    ischemia_mask = None
    hypertrophy_gain = 1.0
    conduction_scale = 1.0
    apd = np.random.uniform(0.22, 0.32)

    if pathology == "ischemia":
        # focal subendocardial-ish region: inner shell band intersect ellipsoid patch
        X, Y, Z = make_grid(n, device)
        r = torch.sqrt(X**2 + Y**2 + (1.3*Z)**2)
        inner_band = torch.sigmoid(25*(r-0.25)) * torch.sigmoid(25*(0.42-r))
        cx, cy, cz = np.random.uniform(-0.25,0.25), np.random.uniform(-0.25,0.25), np.random.uniform(-0.35,0.35)
        rx, ry, rz = np.random.uniform(0.25,0.45), np.random.uniform(0.18,0.35), np.random.uniform(0.18,0.35)
        ell = ((X-cx)/rx)**2 + ((Y-cy)/ry)**2 + ((Z-cz)/rz)**2
        patch = torch.sigmoid(10*(1-ell))
        ischemia = smooth_3d((inner_band*patch), 1.2)
        ischemia = (ischemia / (ischemia.max()+1e-8)).clamp(0,1)
        # enforce size so it isn't invisible
        frac = ischemia.mean().item()
        tries = 0
        while (frac < 0.04 or frac > 0.22) and tries < 6:
            cx, cy, cz = np.random.uniform(-0.25,0.25), np.random.uniform(-0.25,0.25), np.random.uniform(-0.35,0.35)
            rx, ry, rz = np.random.uniform(0.28,0.55), np.random.uniform(0.22,0.40), np.random.uniform(0.22,0.40)
            ell = ((X-cx)/rx)**2 + ((Y-cy)/ry)**2 + ((Z-cz)/rz)**2
            patch = torch.sigmoid(10*(1-ell))
            ischemia = smooth_3d((inner_band*patch), 1.2)
            ischemia = (ischemia / (ischemia.max()+1e-8)).clamp(0,1)
            frac = ischemia.mean().item()
            tries += 1

        ischemia_mask = ischemia
        conduction_scale = np.random.uniform(1.4, 2.2)  # slowed activation
        apd *= np.random.uniform(0.75, 0.95)            # shortened apd

    if pathology == "hypertrophy":
        hypertrophy_gain = np.random.uniform(1.35, 1.85)

    # produce J(t) from gradients of V projected onto fiber directions
    Jt = []
    # base amplitude per subject
    base_amp = np.random.uniform(0.8, 1.2)

    for ti in tvec:
        V = transmembrane_proxy(ti, Tact, apd=apd)
        # ischemia: slower activation + weaker amplitude inside + border injury currents
        if pathology == "ischemia" and ischemia_mask is not None:
            # slowed local activation: shift effective time
            V_iso = transmembrane_proxy(ti, Tact * conduction_scale, apd=apd)
            # blend
            V = V * (1 - ischemia_mask) + V_iso * ischemia_mask
            # reduced amplitude in core
            red = np.random.uniform(0.55, 0.85)
            V = V * (1 - red * ischemia_mask)
            # border injury current term ~ grad(ischemia_mask)
            border = (ischemia_mask * (1 - ischemia_mask) * 4.0).clamp(0,1)
            grad_iso = gradient_scalar(ischemia_mask)
            V = V + 0.15 * border * (grad_iso.norm(dim=0) / (grad_iso.norm(dim=0).max() + 1e-8))

        # gradient -> current proxy
        gV = gradient_scalar(V)  # (3,X,Y,Z)
        # project along fibers (dominant) + transverse (minor)
        along = (gV * fib).sum(dim=0, keepdim=True) * fib
        J = 0.75 * along + 0.25 * gV
        # geometry
        J = J * myo.unsqueeze(0)

        # divergence-free enforcement: add curl(A) component (stabilizes physics)
        A = smooth_3d(torch.randn_like(J), 2.0)
        J = 0.7 * J + 0.3 * curl_of_A(A) * (J.norm(dim=0, keepdim=True).mean() / (curl_of_A(A).norm(dim=0, keepdim=True).mean() + 1e-8))

        # hypertrophy amplitude + mild fiber coherence
        J = J * base_amp * hypertrophy_gain

        # normalize within myocardium only (donâ€™t erase ischemia contrast globally)
        mag = (J.norm(dim=0) * myo).sum() / (myo.sum() + 1e-8)
        J = J / (mag + 1e-8)

        Jt.append(J)

    Jt = torch.stack(Jt, dim=0)  # (T,3,X,Y,Z)
    # pathology-specific overall scaling
    if pathology == "ischemia":
        Jt = Jt * np.random.uniform(0.55, 0.80)
    elif pathology == "normal":
        Jt = Jt * np.random.uniform(0.90, 1.10)
    elif pathology == "arrhythmia":
        Jt = Jt * np.random.uniform(0.95, 1.20)
    elif pathology == "hypertrophy":
        Jt = Jt * np.random.uniform(1.15, 1.55)

    meta = {"apd": apd, "base_amp": base_amp, "hypertrophy_gain": hypertrophy_gain, "conduction_scale": conduction_scale}
    return Jt, meta

# -------------------------
# biot-savart operator (fft, cached)
# -------------------------

class BiotSavartFFT(nn.Module):
    """
    simple B(k) = (i k x J(k)) / |k|^2
    """
    def __init__(self, n: int):
        super().__init__()
        self.n = n
        self.register_buffer("kx", torch.zeros(1), persistent=False)
        self._built = False

    def build(self, device: torch.device, dtype: torch.dtype = torch.float32):
        n = self.n
        k = torch.fft.fftfreq(n, d=1.0, device=device, dtype=dtype)
        kx, ky, kz = torch.meshgrid(k, k, k, indexing="ij")
        k2 = kx**2 + ky**2 + kz**2
        k2[0,0,0] = 1.0
        self.kx = kx
        self.ky = ky
        self.kz = kz
        self.inv_k2 = 1.0 / k2
        self._built = True

    def forward(self, J: torch.Tensor) -> torch.Tensor:
        """
        J: (...,3,X,Y,Z) channel-first in the last 4 dims
        returns B: same shape
        """
        if not self._built or self.kx.device != J.device or self.kx.dtype != J.dtype:
            self.build(J.device, J.dtype)

        # reshape to (B,3,X,Y,Z)
        orig_shape = J.shape
        assert orig_shape[-4] == 3, f"expected channel=3 at -4, got {orig_shape}"
        Bsz = int(np.prod(orig_shape[:-4])) if len(orig_shape) > 4 else 1
        Jv = J.reshape(Bsz, 3, self.n, self.n, self.n)

        Jf = torch.fft.fftn(Jv, dim=(-3,-2,-1))

        kx, ky, kz = self.kx, self.ky, self.kz
        # curl in k-space
        curl_x = ky * Jf[:,2] - kz * Jf[:,1]
        curl_y = kz * Jf[:,0] - kx * Jf[:,2]
        curl_z = kx * Jf[:,1] - ky * Jf[:,0]
        Bf = torch.stack([curl_x, curl_y, curl_z], dim=1) * self.inv_k2  # (B,3,X,Y,Z)
        B = torch.fft.ifftn(Bf, dim=(-3,-2,-1)).real
        return B.reshape(orig_shape)

# -------------------------
# sensor geometry (kiel-compatible)
# -------------------------

KIEL_CHANNEL_AXES = [
    ("sensor0", "-y"),
    ("sensor0", "z"),
    ("sensor1", "-y"),
    ("sensor1", "z"),
    ("sensor2", "-y"),
    ("sensor2", "x"),
    ("sensor3", "-y"),
    ("sensor3", "x"),
]

KIEL_SENSOR_REL_CM = {
    0: (0.0, 0.0, 0.0),
    1: (-3.0, 0.0, 3.0),
    2: (-3.0, 0.0, 0.0),
    3: (0.0, 0.0, 3.0),
}

# trial offset grid per README (y-offset always 0)
# table maps z_offset rows [0,3,6,9,12] and x_offset cols [0,3,6,9,12] to trial index 1..25
KIEL_TRIAL_OFFSETS_CM = {}
# reconstruct from table:
# rows: z=0 -> [trial 1..5] with x=0,3,6,9,12 but table shows columns descending (12,9,6,3,0).
# to avoid confusion, we explicitly map using the table values.
# from README:
# z=0 row: trials [5,4,3,2,1] for x=[12,9,6,3,0]
# z=3 row: [10,9,8,7,6]
# z=6 row: [15,14,13,12,11]
# z=9 row: [20,19,18,17,16]
# z=12 row:[25,24,23,22,21]
def _fill_kiel_trial_offsets():
    xs = [12, 9, 6, 3, 0]
    rows = {
        0:  [5, 4, 3, 2, 1],
        3:  [10,9,8,7,6],
        6:  [15,14,13,12,11],
        9:  [20,19,18,17,16],
        12: [25,24,23,22,21],
    }
    # convert to mapping trial -> (x,z) with y=0
    for z, trials in rows.items():
        for x, trial in zip(xs, trials):
            KIEL_TRIAL_OFFSETS_CM[int(trial)] = (float(x), 0.0, float(z))
_fill_kiel_trial_offsets()

KIEL_INITIAL_ARRAY_POS_CM = (-11.0, 17.0, -14.0)  # sensor0 origin at trial 1 (per README)

def kiel_sensor_positions_cm_for_trial(trial: int) -> Dict[int, Tuple[float,float,float]]:
    """
    returns absolute (x,y,z) in cm for sensors 0..3 for a given trial (1..25),
    using README geometry (initial + offset + relative).
    """
    ox, oy, oz = KIEL_TRIAL_OFFSETS_CM.get(int(trial), (0.0, 0.0, 0.0))
    base = (KIEL_INITIAL_ARRAY_POS_CM[0] + ox, KIEL_INITIAL_ARRAY_POS_CM[1] + oy, KIEL_INITIAL_ARRAY_POS_CM[2] + oz)
    out = {}
    for si in range(4):
        rx, ry, rz = KIEL_SENSOR_REL_CM[si]
        out[si] = (base[0] + rx, base[1] + ry, base[2] + rz)
    return out

def sample_B_at_sensors(
    B_grid: torch.Tensor,
    sensor_pos_cm: Dict[int, Tuple[float,float,float]],
    n: int,
    axes_spec = KIEL_CHANNEL_AXES,
) -> torch.Tensor:
    """
    B_grid: (3,X,Y,Z) in arbitrary units (grid coords [-1,1])
    sensor_pos_cm: positions in cm in patient coordinates
    returns (8,) channels, using axis projections.
    note: mapping cm -> grid coords is unknown without torso scale; we do a simple affine
          mapping that places sensors near the grid surface. domain randomization covers mismatch.
    """
    device = B_grid.device
    # map cm coords to normalized coords roughly: assume +/-20cm fits in [-1,1]
    def cm_to_norm(p):
        return (p[0]/20.0, p[1]/20.0, p[2]/20.0)

    # trilinear sample from grid
    def trilinear_sample(B, xn, yn, zn):
        # coords in [-1,1] -> [0,n-1]
        x = ((xn + 1) * 0.5) * (n - 1)
        y = ((yn + 1) * 0.5) * (n - 1)
        z = ((zn + 1) * 0.5) * (n - 1)
        x0 = int(torch.clamp(torch.floor(torch.tensor(x, device=device)), 0, n-2).item())
        y0 = int(torch.clamp(torch.floor(torch.tensor(y, device=device)), 0, n-2).item())
        z0 = int(torch.clamp(torch.floor(torch.tensor(z, device=device)), 0, n-2).item())
        xd = x - x0
        yd = y - y0
        zd = z - z0
        # fetch corners
        def g(ix, iy, iz):
            return B[:, ix, iy, iz]
        c000 = g(x0, y0, z0)
        c100 = g(x0+1,y0,z0)
        c010 = g(x0,y0+1,z0)
        c001 = g(x0,y0,z0+1)
        c110 = g(x0+1,y0+1,z0)
        c101 = g(x0+1,y0,z0+1)
        c011 = g(x0,y0+1,z0+1)
        c111 = g(x0+1,y0+1,z0+1)
        c00 = c000*(1-xd) + c100*xd
        c01 = c001*(1-xd) + c101*xd
        c10 = c010*(1-xd) + c110*xd
        c11 = c011*(1-xd) + c111*xd
        c0 = c00*(1-yd) + c10*yd
        c1 = c01*(1-yd) + c11*yd
        c = c0*(1-zd) + c1*zd
        return c

    # axis projection vectors (x,y,z)
    axis_map = {
        "x": torch.tensor([1.0, 0.0, 0.0], device=device),
        "y": torch.tensor([0.0, 1.0, 0.0], device=device),
        "z": torch.tensor([0.0, 0.0, 1.0], device=device),
        "-x": torch.tensor([-1.0, 0.0, 0.0], device=device),
        "-y": torch.tensor([0.0, -1.0, 0.0], device=device),
        "-z": torch.tensor([0.0, 0.0, -1.0], device=device),
    }

    chans = []
    for ch in range(8):
        sensor_name, axis = axes_spec[ch]
        si = int(sensor_name.replace("sensor",""))
        xn, yn, zn = cm_to_norm(sensor_pos_cm[si])
        bvec = trilinear_sample(B_grid, xn, yn, zn)  # (3,)
        proj = (bvec * axis_map[axis]).sum()
        chans.append(proj)
    return torch.stack(chans, dim=0)  # (8,)

# -------------------------
# noise + drift for sensor time series
# -------------------------

def add_sensor_noise(
    x: torch.Tensor,  # (B,C,T)
    rel_std: float,
    drift_strength: float,
    line_noise_strength: float,
    fs: int,
) -> torch.Tensor:
    B, C, T = x.shape
    dev = x.device
    # white + correlated
    scale = x.std(dim=-1, keepdim=True).clamp(min=1e-6)
    noise = torch.randn_like(x) * rel_std * scale

    # correlated noise: lowpass filtered noise
    corr = torch.randn_like(x)
    corr = apply_fir(corr, design_fir_lowpass(fs, 25.0, taps=201, device=dev))
    corr = corr * (rel_std * 0.7) * scale

    # drift: random walk + low freq
    rw = torch.randn(B, C, T, device=dev)
    rw = torch.cumsum(rw, dim=-1)
    rw = rw / (rw.std(dim=-1, keepdim=True).clamp(min=1e-6))
    rw = rw * drift_strength * scale

    # line noise 50 hz
    t = torch.arange(T, device=dev).float() / fs
    phase = torch.rand(B, C, 1, device=dev) * 2*math.pi
    line = torch.sin(2*math.pi*50.0*t.view(1,1,-1) + phase)
    line = line * line_noise_strength * scale

    return x + noise + corr + rw + line

# -------------------------
# synthetic dataset (sensor + voxel)
# -------------------------

def class_to_idx(name: str, classes: List[str]) -> int:
    return classes.index(name)

def idx_to_class(i: int, classes: List[str]) -> str:
    return classes[int(i)]

class SyntheticCardiacDataset(Dataset):
    """
    returns:
      sensors: (C=8, T)
      B_grid:  (3,X,Y,Z) (optional)
      J_grid:  (3,X,Y,Z)
      label:   int
    """
    def __init__(self, cfg: TrainConfig, split: str = "train"):
        self.cfg = cfg
        self.split = split
        self.classes = list(cfg.classes)
        self.n = cfg.grid_size
        self.fs = cfg.fs
        self.T = cfg.fs * cfg.seconds

        # split sizes
        n_total = cfg.n_samples
        n_val = int(cfg.val_frac * n_total)
        n_test = int(cfg.test_frac * n_total)
        n_train = n_total - n_val - n_test
        if split == "train":
            self.N = n_train
        elif split == "val":
            self.N = n_val
        else:
            self.N = n_test

        # for reproducibility across splits
        self.base_seed = cfg.seed + (0 if split=="train" else 1234 if split=="val" else 4321)

        self.bs = BiotSavartFFT(self.n)

    def __len__(self):
        return self.N

    def _sample_label(self, i: int) -> int:
        # balanced
        return i % len(self.classes)

    def __getitem__(self, idx: int):
        torch.manual_seed(self.base_seed + idx)
        np.random.seed(self.base_seed + idx)

        label = self._sample_label(idx)
        cname = idx_to_class(label, self.classes)

        # random heart rate affects time warp
        hr = np.random.uniform(*self.cfg.heart_rate_bpm_range)
        rr = 60.0 / hr
        seconds = self.cfg.seconds
        # generate J(t)
        Jt, meta = synthesize_J_time_series(self.n, torch.device(self.cfg.device), self.fs, seconds, cname)
        # time warp to HR by resampling within window
        # (keep length fixed T)
        t = torch.linspace(0, seconds, self.T, device=Jt.device)
        t_warp = (t / seconds) * (seconds / rr)  # more beats if rr small
        t_warp = (t_warp - t_warp.min()) / (t_warp.max() - t_warp.min() + 1e-8) * (seconds - 1e-6)
        # sample nearest indices
        idxs = torch.clamp((t_warp / seconds * (Jt.shape[0]-1)).long(), 0, Jt.shape[0]-1)
        J = Jt[idxs].mean(dim=0)  # collapse time into one representative frame for inversion/classification
        # if you want full time inversion, expand this (kept stable for one-file)

        # forward B grid
        B = self.bs(J.unsqueeze(0)).squeeze(0)  # (3,X,Y,Z)

        # sensors
        if self.cfg.sensor_mode == "kiel":
            trial = int(np.random.randint(1, 26))
            spos = kiel_sensor_positions_cm_for_trial(trial)
        else:
            # random around torso
            spos = {si: (np.random.uniform(-12,12), np.random.uniform(8,22), np.random.uniform(-12,12)) for si in range(4)}

        # build an 8xT sensor timeseries by adding simple beat-like temporal modulation
        # (the real MCG is time series; we emulate with a scalar cardiac waveform)
        # waveform: sum of gaussians (QRS-like) + slower T wave
        tt = torch.arange(self.T, device=J.device).float() / self.fs
        qrs_center = np.random.uniform(1.2, 1.8)
        t_center = qrs_center + np.random.uniform(0.22, 0.32)
        qrs = torch.exp(-0.5*((tt-qrs_center)/0.03)**2) - 0.5*torch.exp(-0.5*((tt-(qrs_center+0.04))/0.06)**2)
        tw = 0.45*torch.exp(-0.5*((tt-t_center)/0.09)**2)
        wave = (qrs + tw).view(1, -1)  # (1,T)
        wave = wave / (wave.abs().max() + 1e-8)

        # sample B at sensors once then modulate over time
        b0 = sample_B_at_sensors(B, spos, self.n)  # (8,)
        sensors = b0.view(-1,1) * wave  # (8,T)

        # noise + kiel preprocess
        sensors = sensors.unsqueeze(0)  # (1,8,T)
        sensors = add_sensor_noise(
            sensors,
            rel_std=self.cfg.sensor_noise_std,
            drift_strength=self.cfg.drift_strength,
            line_noise_strength=self.cfg.line_noise_strength,
            fs=self.fs,
        )
        sensors = kiel_preprocess(sensors, fs=self.fs, randomize=self.cfg.domain_randomize_filters)
        sensors = sensors.squeeze(0)  # (8,T)

        # optional voxel augment
        J_aug = J.clone()
        B_aug = B.clone()
        if self.split == "train":
            # random shift
            sh = self.cfg.aug_shift_vox
            if sh > 0:
                shifts = [int(np.random.randint(-sh, sh+1)) for _ in range(3)]
                J_aug = torch.roll(J_aug, shifts=shifts, dims=(-3,-2,-1))
                B_aug = torch.roll(B_aug, shifts=shifts, dims=(-3,-2,-1))
            # additive noise
            if self.cfg.aug_noise_vox > 0:
                J_aug = J_aug + torch.randn_like(J_aug) * self.cfg.aug_noise_vox * J_aug.std().clamp(min=1e-6)
                B_aug = B_aug + torch.randn_like(B_aug) * self.cfg.aug_noise_vox * B_aug.std().clamp(min=1e-6)

        return {
            "sensors": sensors.detach().cpu(),  # keep dataset on cpu for dataloader stability
            "B": B_aug.detach().cpu(),
            "J": J_aug.detach().cpu(),
            "label": torch.tensor(label, dtype=torch.long),
            "meta": {"hr": hr, **meta},
        }

# -------------------------
# kiel-cardio loader (wfdb optional)
# -------------------------

class KielCardioDataset(Dataset):
    """
    loads kiel-cardio wfdb records:
      - returns sensors (8,T), fs parsed from header, and optional positions parsed from header fields
    expects directory structure:
      kiel_root/
        data/
          subject1_preprocessed_trial01.dat/.hea ...
    """
    def __init__(self, kiel_root: str, use_preprocessed: bool = True, max_records: int = 999999):
        self.kiel_root = kiel_root
        self.use_pre = use_preprocessed
        self.data_dir = os.path.join(kiel_root, "data")
        assert os.path.isdir(self.data_dir), f"could not find data dir: {self.data_dir}"

        tag = "preprocessed" if use_preprocessed else "raw"
        self.records = sorted([p[:-4] for p in glob.glob(os.path.join(self.data_dir, f"subject*_{tag}_trial*.hea"))])
        self.records = self.records[:max_records]

        # wfdb optional
        try:
            import wfdb  # type: ignore
            self.wfdb = wfdb
        except Exception:
            self.wfdb = None

    def __len__(self):
        return len(self.records)

    def _parse_positions_from_hea(self, hea_text: str) -> Optional[Dict[str, Tuple[float,float,float]]]:
        # headers include position sensor i [cm] fields per README; formats can vary.
        # we attempt a robust parse: look for "position sensor X [cm]" or "SensorX pos" patterns.
        # if not found, return None.
        # in physionet headers, extra fields may appear after signal lines.
        # we'll parse any triplets of floats following "position sensor <i>".
        pos = {}
        for si in range(4):
            m = re.search(rf"position\s*sensor\s*{si}.*?\(([-\d\.]+),\s*([-\d\.]+),\s*([-\d\.]+)\)", hea_text, re.IGNORECASE)
            if m:
                pos[str(si)] = (float(m.group(1)), float(m.group(2)), float(m.group(3)))
        return pos if len(pos) == 4 else None

    def __getitem__(self, idx: int):
        rec = self.records[idx]
        hea_path = rec + ".hea"
        with open(hea_path, "r", encoding="utf-8", errors="ignore") as f:
            hea = f.read()

        # parse fs from first line: "<record> <nsig> <fs> <nsamp>"
        fs = 200
        first = hea.strip().splitlines()[0].strip().split()
        if len(first) >= 3:
            try:
                fs = int(float(first[2]))
            except Exception:
                fs = 200

        if self.wfdb is None:
            # still return something useful + instructions
            raise RuntimeError(
                "wfdb python package not installed. install with: pip install wfdb\n"
                f"then rerun. record header parsed ok (fs={fs}), but signal loading needs wfdb."
            )

        # wfdb reads by record name without extension
        # rec is full path; wfdb wants record_name and pn_dir, but can also accept full path
        record = self.wfdb.rdrecord(rec)
        sig = record.p_signal  # (T,8)
        sig = torch.tensor(sig.T, dtype=torch.float32)  # (8,T)

        # if raw, you may want to apply kiel_preprocess here; if preprocessed, skip
        if not self.use_pre:
            sig = kiel_preprocess(sig.unsqueeze(0), fs=fs, randomize=False).squeeze(0)

        # standardize per record
        sig = (sig - sig.mean(dim=-1, keepdim=True)) / (sig.std(dim=-1, keepdim=True).clamp(min=1e-6))

        pos = self._parse_positions_from_hea(hea)
        return {"sensors": sig, "fs": fs, "positions_cm": pos, "record": os.path.basename(rec)}

# -------------------------
# models
# -------------------------

class EMA:
    def __init__(self, model: nn.Module, decay: float):
        self.decay = decay
        self.shadow = {k: v.detach().clone() for k, v in model.state_dict().items() if v.dtype.is_floating_point}
        self.backup = {}

    @torch.no_grad()
    def update(self, model: nn.Module):
        for k, v in model.state_dict().items():
            if k in self.shadow and v.dtype.is_floating_point:
                self.shadow[k].mul_(self.decay).add_(v.detach(), alpha=1 - self.decay)

    def apply_to(self, model: nn.Module):
        self.backup = {}
        sd = model.state_dict()
        for k in self.shadow:
            self.backup[k] = sd[k].detach().clone()
            sd[k].copy_(self.shadow[k])

    def restore(self, model: nn.Module):
        sd = model.state_dict()
        for k, v in self.backup.items():
            sd[k].copy_(v)
        self.backup = {}

class SpectralConv3d(nn.Module):
    """
    stable FNO-ish spectral conv (not full FNO, but robust in one file).
    input: (B,C,X,Y,Z)
    """
    def __init__(self, in_channels: int, out_channels: int, modes: int):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.modes = modes
        self.scale = 1 / (in_channels * out_channels)
        # complex weights
        self.weight = nn.Parameter(self.scale * torch.randn(in_channels, out_channels, modes, modes, modes, 2))

    def compl_mul3d(self, input_fft, weights):
        # input_fft: (B,in, X,Y,Z) complex
        # weights: (in,out,mx,my,mz) complex
        return torch.einsum("bixyz,ioxyz->boxyz", input_fft, weights)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, C, X, Y, Z = x.shape
        x_ft = torch.fft.rfftn(x, dim=(-3,-2,-1))
        mx = min(self.modes, X)
        my = min(self.modes, Y)
        mz = min(self.modes, x_ft.shape[-1])

        weight = torch.view_as_complex(self.weight)  # (in,out,m,m,m)

        out_ft = torch.zeros(B, self.out_channels, X, Y, x_ft.shape[-1], device=x.device, dtype=torch.cfloat)
        out_ft[:, :, :mx, :my, :mz] = self.compl_mul3d(x_ft[:, :, :mx, :my, :mz], weight[:, :, :mx, :my, :mz])
        x = torch.fft.irfftn(out_ft, s=(X,Y,Z), dim=(-3,-2,-1))
        return x

class Spectral3DInversionNet(nn.Module):
    """
    B -> J inversion on voxel grid.
    input:  (B,3,X,Y,Z)
    output: (B,3,X,Y,Z)
    """
    def __init__(self, width: int = 48, depth: int = 4, modes: int = 10):
        super().__init__()
        self.fc0 = nn.Conv3d(3, width, 1)
        self.layers = nn.ModuleList()
        for _ in range(depth):
            self.layers.append(nn.ModuleList([
                SpectralConv3d(width, width, modes),
                nn.Conv3d(width, width, 1),
                nn.GroupNorm(8, width),
            ]))
        self.fc1 = nn.Conv3d(width, width, 1)
        self.fc2 = nn.Conv3d(width, 3, 1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.fc0(x)
        for spec, conv, gn in self.layers:
            y = spec(x) + conv(x)
            y = gn(y)
            x = F.gelu(y)
        x = F.gelu(self.fc1(x))
        x = self.fc2(x)
        return x

class CNN3DClassifier(nn.Module):
    """
    classifier on J with physics features:
      input channels = 3 + |J| + div(J) = 5
    """
    def __init__(self, in_ch: int = 5, width: int = 48, n_classes: int = 4):
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv3d(in_ch, width, 3, padding=1),
            nn.GroupNorm(8, width),
            nn.GELU(),
        )
        self.blocks = nn.Sequential(
            nn.Conv3d(width, width*2, 3, padding=1, stride=2),
            nn.GroupNorm(8, width*2),
            nn.GELU(),
            nn.Conv3d(width*2, width*2, 3, padding=1),
            nn.GroupNorm(8, width*2),
            nn.GELU(),

            nn.Conv3d(width*2, width*4, 3, padding=1, stride=2),
            nn.GroupNorm(8, width*4),
            nn.GELU(),
            nn.Conv3d(width*4, width*4, 3, padding=1),
            nn.GroupNorm(8, width*4),
            nn.GELU(),
        )
        self.head = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),
            nn.Flatten(),
            nn.Linear(width*4, width*2),
            nn.GELU(),
            nn.Dropout(0.15),
            nn.Linear(width*2, n_classes),
        )

    def forward(self, J5: torch.Tensor) -> torch.Tensor:
        x = self.stem(J5)
        x = self.blocks(x)
        return self.head(x)

class SensorTransformer(nn.Module):
    """
    1d transformer encoder for 8-channel time series, returns logits + embedding.
    """
    def __init__(self, n_classes: int = 4, d_model: int = 128, nhead: int = 8, depth: int = 4):
        super().__init__()
        self.proj = nn.Conv1d(8, d_model, 7, padding=3)
        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, batch_first=True, dropout=0.1, activation="gelu")
        self.enc = nn.TransformerEncoder(enc_layer, num_layers=depth)
        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))
        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_classes))
        self.embed_head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, d_model))

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        # x: (B,8,T)
        h = self.proj(x).transpose(1,2)  # (B,T,d)
        cls = self.cls.repeat(h.size(0), 1, 1)
        h = torch.cat([cls, h], dim=1)
        h = self.enc(h)
        z = h[:, 0]  # cls token
        logits = self.head(z)
        emb = self.embed_head(z)
        return logits, emb

# -------------------------
# losses
# -------------------------

class FocalLoss(nn.Module):
    def __init__(self, gamma: float = 1.5, weight: Optional[torch.Tensor] = None, label_smoothing: float = 0.0):
        super().__init__()
        self.gamma = gamma
        self.weight = weight
        self.label_smoothing = label_smoothing

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        # label smoothing
        n = logits.size(-1)
        if self.label_smoothing > 0:
            with torch.no_grad():
                true_dist = torch.zeros_like(logits)
                true_dist.fill_(self.label_smoothing / (n - 1))
                true_dist.scatter_(1, targets.unsqueeze(1), 1 - self.label_smoothing)
            logp = F.log_softmax(logits, dim=-1)
            p = logp.exp()
            if self.weight is not None:
                w = self.weight.view(1, -1)
                loss = -(true_dist * w * ((1 - p) ** self.gamma) * logp).sum(dim=-1).mean()
            else:
                loss = -(true_dist * ((1 - p) ** self.gamma) * logp).sum(dim=-1).mean()
            return loss
        else:
            logp = F.log_softmax(logits, dim=-1)
            p = logp.exp()
            pt = p.gather(1, targets.unsqueeze(1)).squeeze(1)
            logpt = logp.gather(1, targets.unsqueeze(1)).squeeze(1)
            if self.weight is not None:
                at = self.weight.gather(0, targets)
                loss = -at * ((1 - pt) ** self.gamma) * logpt
            else:
                loss = -((1 - pt) ** self.gamma) * logpt
            return loss.mean()

def smoothness_loss(J: torch.Tensor) -> torch.Tensor:
    # total variation-ish
    dx = (J[...,1:,:,:] - J[...,:-1,:,:]).abs().mean()
    dy = (J[...,:,1:,:] - J[...,:,:-1,:]).abs().mean()
    dz = (J[...,:,:,1:] - J[...,:,:, :-1]).abs().mean()
    return dx + dy + dz

def make_J_features(J: torch.Tensor) -> torch.Tensor:
    """
    J: (B,3,X,Y,Z)
    returns (B,5,X,Y,Z) = [J, |J|, div(J)]
    """
    mag = J.norm(dim=1, keepdim=True)
    div = divergence(J)  # (B,X,Y,Z)
    div = div.unsqueeze(1)
    return torch.cat([J, mag, div], dim=1)

# -------------------------
# mixup
# -------------------------

def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float):
    if alpha <= 0:
        return x, y, None
    lam = np.random.beta(alpha, alpha)
    idx = torch.randperm(x.size(0), device=x.device)
    x_mix = lam * x + (1 - lam) * x[idx]
    y_a, y_b = y, y[idx]
    return x_mix, y_a, y_b, lam

def mixup_criterion(loss_fn, pred, y_a, y_b, lam):
    return lam * loss_fn(pred, y_a) + (1 - lam) * loss_fn(pred, y_b)

# -------------------------
# train loops
# -------------------------

def stratified_split_indices(n: int, n_classes: int, val_frac: float, test_frac: float, seed: int):
    # since our dataset is balanced by construction, simple deterministic split is ok
    idxs = np.arange(n)
    rng = np.random.RandomState(seed)
    rng.shuffle(idxs)
    n_val = int(val_frac * n)
    n_test = int(test_frac * n)
    val = idxs[:n_val]
    test = idxs[n_val:n_val+n_test]
    train = idxs[n_val+n_test:]
    return train.tolist(), val.tolist(), test.tolist()

class SubsetWrap(Dataset):
    def __init__(self, base: Dataset, indices: List[int]):
        self.base = base
        self.indices = indices
    def __len__(self):
        return len(self.indices)
    def __getitem__(self, i):
        return self.base[self.indices[i]]

def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:
    # keep meta as list
    out = {}
    out["sensors"] = torch.stack([b["sensors"] for b in batch], dim=0)  # (B,8,T)
    out["B"] = torch.stack([b["B"] for b in batch], dim=0)              # (B,3,X,Y,Z)
    out["J"] = torch.stack([b["J"] for b in batch], dim=0)              # (B,3,X,Y,Z)
    out["label"] = torch.stack([b["label"] for b in batch], dim=0)      # (B,)
    out["meta"] = [b["meta"] for b in batch]
    return out

def train_inversion(cfg: TrainConfig, model: nn.Module, train_dl: DataLoader, val_dl: DataLoader) -> nn.Module:
    device = torch.device(cfg.device)
    model = model.to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)
    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(cfg.epochs_inv, 1))
    ema = EMA(model, cfg.ema_decay)

    best_val = float("inf")
    best_state = None
    patience = 0

    for ep in range(cfg.epochs_inv):
        t0 = time.time()
        model.train()
        total = 0.0
        steps = 0

        for batch in train_dl:
            batch = to_device(batch, device)
            B = batch["B"]  # (B,3,X,Y,Z)
            J = batch["J"]

            pred = model(B)
            mse = F.mse_loss(pred, J)
            div = divergence(pred).abs().mean()
            sm = smoothness_loss(pred)

            loss = mse + cfg.lambda_div * div + cfg.lambda_smooth * sm

            opt.zero_grad(set_to_none=True)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)
            opt.step()
            ema.update(model)

            total += loss.item()
            steps += 1

        sch.step()

        # val with ema
        ema.apply_to(model)
        model.eval()
        vtot = 0.0
        vsteps = 0
        with torch.no_grad():
            for batch in val_dl:
                batch = to_device(batch, device)
                B = batch["B"]
                J = batch["J"]
                pred = model(B)
                mse = F.mse_loss(pred, J)
                div = divergence(pred).abs().mean()
                sm = smoothness_loss(pred)
                loss = mse + cfg.lambda_div * div + cfg.lambda_smooth * sm
                vtot += loss.item()
                vsteps += 1
        ema.restore(model)

        tr = total / max(steps,1)
        va = vtot / max(vsteps,1)
        dt = pretty_time(time.time() - t0)
        print(f"[inv] ep {ep+1:03d}/{cfg.epochs_inv} | train {tr:.4f} | val {va:.4f} | {dt}")

        if va < best_val - 1e-5:
            best_val = va
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}
            patience = 0
        else:
            patience += 1
            if patience >= cfg.early_stop_patience:
                print("[inv] early stop")
                break

    if best_state is not None:
        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})
    return model

def train_classifier_on_reconJ(
    cfg: TrainConfig,
    inv: nn.Module,
    clf: nn.Module,
    train_dl: DataLoader,
    val_dl: DataLoader,
) -> nn.Module:
    device = torch.device(cfg.device)
    inv = inv.to(device).eval()
    clf = clf.to(device)

    # class weights: boost ischemia
    n_classes = len(cfg.classes)
    w = torch.ones(n_classes, device=device)
    ischemia_idx = list(cfg.classes).index("ischemia") if "ischemia" in cfg.classes else None
    if ischemia_idx is not None:
        w[ischemia_idx] *= cfg.class_weight_ischemia_boost

    loss_fn = FocalLoss(gamma=cfg.focal_gamma, weight=w, label_smoothing=cfg.label_smoothing)

    opt = torch.optim.AdamW(clf.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)
    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(cfg.epochs_clf, 1))
    ema = EMA(clf, cfg.ema_decay)

    best_val = -1.0
    best_state = None
    patience = 0

    for ep in range(cfg.epochs_clf):
        t0 = time.time()
        clf.train()
        total = 0.0
        steps = 0

        for batch in train_dl:
            batch = to_device(batch, device)
            B = batch["B"]
            y = batch["label"]

            with torch.no_grad():
                Jhat = inv(B)
            Jfeat = make_J_features(Jhat)

            # mixup in feature space (stable)
            if cfg.mixup_alpha > 0:
                Jmix, ya, yb, lam = mixup(Jfeat, y, cfg.mixup_alpha)
                logits = clf(Jmix)
                loss = mixup_criterion(loss_fn, logits, ya, yb, lam)
            else:
                logits = clf(Jfeat)
                loss = loss_fn(logits, y)

            opt.zero_grad(set_to_none=True)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(clf.parameters(), cfg.grad_clip)
            opt.step()
            ema.update(clf)

            total += loss.item()
            steps += 1

        sch.step()

        # val
        ema.apply_to(clf)
        clf.eval()
        all_p, all_y = [], []
        with torch.no_grad():
            for batch in val_dl:
                batch = to_device(batch, device)
                B = batch["B"]
                y = batch["label"]
                Jhat = inv(B)
                Jfeat = make_J_features(Jhat)
                logits = clf(Jfeat)
                p = logits.argmax(dim=-1)
                all_p.append(p.cpu())
                all_y.append(y.cpu())
        ema.restore(clf)

        p = torch.cat(all_p, dim=0)
        y = torch.cat(all_y, dim=0)
        cm = confusion_matrix(p, y, n_classes)
        rep = classification_report_from_cm(cm, list(cfg.classes))
        acc = rep["accuracy"]
        macro_f1 = rep["macro_f1"]

        tr = total / max(steps, 1)
        dt = pretty_time(time.time() - t0)
        print(f"[clf] ep {ep+1:03d}/{cfg.epochs_clf} | trainloss {tr:.4f} | val acc {acc:.3f} | val f1 {macro_f1:.3f} | {dt}")

        if macro_f1 > best_val + 1e-4:
            best_val = macro_f1
            best_state = {k: v.detach().cpu().clone() for k, v in clf.state_dict().items()}
            patience = 0
        else:
            patience += 1
            if patience >= cfg.early_stop_patience:
                print("[clf] early stop")
                break

    if best_state is not None:
        clf.load_state_dict({k: v.to(device) for k, v in best_state.items()})
    return clf

@torch.no_grad()
def evaluate_synthetic(cfg: TrainConfig, inv: nn.Module, clf: nn.Module, test_dl: DataLoader) -> Dict[str, Any]:
    device = torch.device(cfg.device)
    inv = inv.to(device).eval()
    clf = clf.to(device).eval()
    all_p, all_y = [], []
    for batch in test_dl:
        batch = to_device(batch, device)
        B = batch["B"]
        y = batch["label"]
        Jhat = inv(B)
        Jfeat = make_J_features(Jhat)
        logits = clf(Jfeat)
        p = logits.argmax(dim=-1)
        all_p.append(p.cpu())
        all_y.append(y.cpu())
    p = torch.cat(all_p, dim=0)
    y = torch.cat(all_y, dim=0)
    cm = confusion_matrix(p, y, len(cfg.classes))
    rep = classification_report_from_cm(cm, list(cfg.classes))
    rep["confusion_matrix"] = cm.tolist()
    return rep

# -------------------------
# kiel compatibility evaluation (unlabeled)
# -------------------------

@torch.no_grad()
def kiel_realism_checks(cfg: TrainConfig, sensor_model: SensorTransformer, kiel_ds: KielCardioDataset):
    """
    no disease labels in kiel v1.0.0, so we do:
      - embedding extraction
      - simple clustering stats / subject separation proxy (unsupervised)
      - reconstruction-style masked modeling score (optional hook)
    """
    device = torch.device(cfg.device)
    sensor_model = sensor_model.to(device).eval()

    dl = DataLoader(kiel_ds, batch_size=8, shuffle=False, num_workers=0)
    embs = []
    recs = []
    for batch in dl:
        x = batch["sensors"].to(device)  # (B,8,T)
        # ensure fs=200-ish; if not, you should resample (kept minimal)
        logits, z = sensor_model(x)
        embs.append(z.cpu())
        recs.extend(batch["record"])
        if len(recs) >= cfg.kiel_max_records:
            break
    Z = torch.cat(embs, dim=0)
    # pairwise distances summary
    d = torch.cdist(Z, Z)
    # report median intra-set distance (crude)
    print(f"[kiel] embeddings: {Z.shape}, pairwise dist median={d.median().item():.4f}, mean={d.mean().item():.4f}")

# -------------------------
# main
# -------------------------

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--grid_size", type=int, default=None)
    parser.add_argument("--n_samples", type=int, default=None)
    parser.add_argument("--epochs_inv", type=int, default=None)
    parser.add_argument("--epochs_clf", type=int, default=None)
    parser.add_argument("--device", type=str, default=None)
    parser.add_argument("--kiel_root", type=str, default=None)
    parser.add_argument("--run_kiel", action="store_true")
    args = parser.parse_args()

    cfg = TrainConfig()
    if args.grid_size is not None: cfg.grid_size = args.grid_size
    if args.n_samples is not None: cfg.n_samples = args.n_samples
    if args.epochs_inv is not None: cfg.epochs_inv = args.epochs_inv
    if args.epochs_clf is not None: cfg.epochs_clf = args.epochs_clf
    if args.device is not None: cfg.device = args.device
    if args.kiel_root is not None: cfg.kiel_root = args.kiel_root

    seed_all(cfg.seed)
    print("[cfg]", json.dumps(asdict(cfg), indent=2))

    # build synthetic datasets
    base_train = SyntheticCardiacDataset(cfg, split="train")
    base_val = SyntheticCardiacDataset(cfg, split="val")
    base_test = SyntheticCardiacDataset(cfg, split="test")

    train_dl = DataLoader(base_train, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, collate_fn=collate_fn, drop_last=True)
    val_dl = DataLoader(base_val, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, collate_fn=collate_fn)
    test_dl = DataLoader(base_test, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, collate_fn=collate_fn)

    # models
    inv = Spectral3DInversionNet(width=cfg.inv_width, depth=cfg.inv_depth, modes=cfg.inv_modes)
    clf = CNN3DClassifier(in_ch=5, width=cfg.clf_width, n_classes=len(cfg.classes))

    # train inversion + classifier
    inv = train_inversion(cfg, inv, train_dl, val_dl)
    clf = train_classifier_on_reconJ(cfg, inv, clf, train_dl, val_dl)

    # evaluate synthetic
    rep = evaluate_synthetic(cfg, inv, clf, test_dl)
    print("\n[synth] report:", json.dumps({k: v for k, v in rep.items() if k != "per_class"}, indent=2))
    print("[synth] per-class:")
    for k, v in rep["per_class"].items():
        print(f"  - {k:12s} prec={v['precision']:.3f} rec={v['recall']:.3f} f1={v['f1']:.3f} n={v['support']}")
    print("[synth] confusion matrix (rows=true, cols=pred):")
    for row in rep["confusion_matrix"]:
        print("  ", row)

    # kiel compatibility mode (unlabeled realism / embedding stats)
    if args.run_kiel:
        if not cfg.kiel_root:
            raise ValueError("--run_kiel requires --kiel_root pointing to extracted kiel-cardio/1.0.0 folder")
        kiel_ds = KielCardioDataset(cfg.kiel_root, use_preprocessed=cfg.kiel_use_preprocessed, max_records=cfg.kiel_max_records)
        sensor_model = SensorTransformer(n_classes=len(cfg.classes), d_model=128, nhead=8, depth=4)
        # you can (and should) pretrain this on kiel self-supervised in a real project
        kiel_realism_checks(cfg, sensor_model, kiel_ds)

if __name__ == "__main__":
    main()
